{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from autowoe import AutoWoE, ReportDeco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и подготовка обучающей выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    \"./data/train_demo.csv\", low_memory=False, index_col=\"line_id\", parse_dates=[\"datetime_\" + str(i) for i in range(2)]\n",
    ")\n",
    "\n",
    "train = train.iloc[:, 50:100]\n",
    "\n",
    "num_col = list(filter(lambda x: \"numb\" in x, train.columns))\n",
    "num_feature_type = dict.fromkeys(num_col, \"real\")\n",
    "\n",
    "date_col = filter(lambda x: \"datetime\" in x, train.columns)\n",
    "for col in date_col:\n",
    "    train[col + \"_year\"] = train[col].map(lambda x: x.year)\n",
    "    train[col + \"_weekday\"] = train[col].map(lambda x: x.weekday())\n",
    "    train[col + \"_month\"] = train[col].map(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение и подготовка тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test_demo.csv\", index_col=\"line_id\", parse_dates=[\"datetime_\" + str(i) for i in range(2)])\n",
    "\n",
    "date_col = filter(lambda x: \"datetime\" in x, test.columns)\n",
    "for col in date_col:\n",
    "    test[col + \"_year\"] = test[col].map(lambda x: x.year)\n",
    "    test[col + \"_weekday\"] = test[col].map(lambda x: x.weekday())\n",
    "    test[col + \"_month\"] = test[col].map(lambda x: x.month)\n",
    "\n",
    "test_target = pd.read_csv(\"./data/test-target_demo.csv\")[\"target\"]\n",
    "test[\"target\"] = test_target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для обучения модели рекомендуется указать тип признаков для обучения.\n",
    "Поэтому создается словарь features_type с ключами: \n",
    "\n",
    "\n",
    "\"real\" -- вещественный признак,\n",
    "\n",
    "\"cat\" --  категориальный.\n",
    "\n",
    "Для признаков, которые не размечены, типы будут определены автоматом. Такой вариант будет работать, но качество порядочно просядет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### features_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = list(filter(lambda x: \"str\" in x, train.columns))\n",
    "cat_feature_type = dict.fromkeys(cat_col, \"cat\")\n",
    "\n",
    "year_col = list(filter(lambda x: \"_year\" in x, train.columns))\n",
    "year_feature_type = dict.fromkeys(year_col, \"cat\")\n",
    "\n",
    "weekday_col = list(filter(lambda x: \"_weekday\" in x, train.columns))\n",
    "weekday_feature_type = dict.fromkeys(weekday_col, \"cat\")\n",
    "\n",
    "month_col = list(filter(lambda x: \"_month\" in x, train.columns))\n",
    "month_feature_type = dict.fromkeys(month_col, \"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cat_col + year_col + weekday_col + month_col + num_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature level constrains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_type = dict(\n",
    "    **num_feature_type, **cat_feature_type, **year_feature_type, **weekday_feature_type, **month_feature_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `features_monotone_constraints` - также можно указать зависимость целевой переменной от признака. Если заранее известно, что при возрастании признака feature_1, то эту информацию можно учесть в модели, добавив в словарь пару {feature_1: \"1\"}. Если же зависимость признака от целевой переменной обратная, то можно указать {feature_1: \"-1\"} Если про зависимость ничего неизвестно, но хочется, чтобы она была монотонная, можно указать 'auto'. Можно указать  {feature_1: \"0\"}, в случае, если установлено общее ограничение на монотонность, чтобы не распространять его на эту фичу. Если специальных условий нет, то можно не собирать этот дикт\n",
    "\n",
    "\n",
    "Рекомендуемое использование:\n",
    "\n",
    "1) В случае, если задано общее условие на монотонность, то можно собрать дикт {feature_1: \"0\", feature_2: \"0\"}, чтобы игнорировать это ограничение для признаков feature_1, feature_2\n",
    "\n",
    "2) В случае, если не задано общее условие на монотонность, то можно собрать дикт {feature_1: \"auto\", feature_2: \"auto\"}, чтобы установить это ограничение для признаков feature_1, feature_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_monotone_constraints = {\"number_74\": \"auto\", \"number_83\": \"auto\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `max_bin_count`  - через словарь max_bin_count можно задать число бинов для WoE кодирования, если для какого-то признака оно отлично от общего. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bin_count = {\"number_47\": 3, \"number_51\": 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Рекомендация\n",
    "В общем случае, в первый момент построения модели лучше не указывать специальных ограничений в features_monotone_constraints и max_bin_count. Если в результате анализа полученной модели разбиение оказалось неинтерпретируемым или нестабильным по отдельным признакам, но в целом по модели ок, то ограничить сложность разбиения отдельных призаков имеет смысл. Если разбивка большинства признаков в модели оказалась неудовлетворительная, то рекомендуется в первую очередь настраивать глобальные ограничения (см параметры модели max_bin_count, monotonic, min_bin_size и др ниже)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Общие параметры модели\n",
    "\n",
    "- `interpreted_model` - требуется ли интерпретируемость модели (условие на знак в коэффициентах логистической регрессии)\n",
    "\n",
    "- `monotonic` - Глобальное условие на монотонность. Если указано True, то для всех признаков по умолчанию будут строится только монотонные разбиения. Указать специальные условия для отдельных признаков можно используя features_monotone_constraints аргумент метода .fit\n",
    "\n",
    "- `max_bin_count` - Глобальное ограничение на число бинов. Указать специальные условия для отдельных признаков можно используя max_bin_count аргумент метода .fit\n",
    "\n",
    "- `select_type`  - способ ПРЕДВАРИТЕЛЬНОГО!!! (ЭТО ВАЖНО) отбора признаков. Если указать None, то будут отобраны признаки, у которых importance больше imp_th. Если указвать, например 50, то после предварительного отобра останется только 50 признаков самых важных признаков. Крайне не рекомендуется сильно ограничивать\n",
    "\n",
    "- `pearson_th` - пороговое значен для корреляции Пирсона. Используется на финальной стадии отбора признаков.\n",
    "Если корреляция вух признаков по модулю больше pearson_th, то будет выброшен тот, у которого \n",
    "информативность меньше\n",
    "\n",
    "- `auc_th` - пороговое значнеи для одномерной оценки качества признака\n",
    "\n",
    "- `vif_th` - пороговое значнеи для VIF признака\n",
    "\n",
    "- `imp_th` - порог по которому будет произведен отбор признаков, если указать select_type=None (см. ниже).\n",
    "\n",
    "- `th_const` порог по которому признак будет считаться константным. Все константные признаки в модели не учитываются. Если число валидных значений больше трешхолда, то колонка не константная (int). В случае указания float, трешхолд будет определяться как размер_выборки * th_const\n",
    "\n",
    "- `force_single_split` - иногда в силу ограничений на min_bin_size невозможно построить ниодной группировки на переменную. force_single_split=True заставит в этом случае построить единственно возмоджный сплит, в случае если при этом выделяется группа размера более чем th_const. False будет выкидывать этот признак\n",
    "\n",
    "\n",
    "- `th_nan` - порог по которому будет выделена отдельная категория для пропусков в данных.\n",
    "Если число пропусков меньше чем th_nan, то WoE значения для пропусков берется равным нулю.\n",
    "В противном случае пропущенные значения будут выделены в отдельную группу и для них отдельно\n",
    "будет рассчитано WoE значение.\n",
    "Так же влияет на редкие категории (менее th_cat). Если суммарно таких категорий будет менее th_nan, то обработка будет производиться по принципу отпределенному в `cat_merge_to`, иначе оценено по группе\n",
    "\n",
    "- `th_cat` - порог, по которой немногочисленные категории в категориальных признаках будут объединятся в отдельную группу\n",
    "\n",
    "\n",
    "- `woe_diff_th` - Возмодность смеджить наны и редкие категории с каким-то бином, если разница в вое менее woe_diff_th\n",
    "\n",
    "\n",
    "- `min_bin_size` - минимальный размер бина при группировке. Возможно int как число наблюдений и float как доля от выбрки\n",
    "\n",
    "- `min_bin_mults` - в ходе построения бинов будут протестированы возможные значения min_bin_size, \n",
    "min_bin_size * min_bin_mults[0], min_bin_size * min_bin_mults[1] ... . Ждем float > 1. Дефолт - (2, 4), в принципе можно не трогать\n",
    "\n",
    "- `min_gains_to_split` - возможные значения регуляризатора, которые будут протестированы в ходе построения биннинга\n",
    "\n",
    "\n",
    "- `auc_tol` - Чувствительность к AUC. Считаем, что можем пожертвовать auc_tol качества от максимального, чтобы сделать модель проще\n",
    "\n",
    "\n",
    "- `cat_alpha` - Регуляризатор для кодировщика категорий\n",
    "\n",
    "\n",
    "\n",
    "- `cat_merge_to` - группа для редких (менее th_cat) категорий либо новых на тесте\n",
    "         \"to_nan\" -- в группу nan, \n",
    "         \"to_woe_0\" -- отдельная группа с WoE = 0,\n",
    "         \"to_maxfreq\" - в самую большую группу,\n",
    "         \"to_maxp\" - в группу с наибольшей вероятностью события,\n",
    "         \"to_minp\" - в группу с наименьшей вероятностью события\n",
    "         \n",
    "- `nan_merge_to` - группа для НаНов\n",
    "         \"to_woe_0\" -- отдельная группа с WoE = 0,\n",
    "         \"to_maxfreq\" - в самую большую группу,\n",
    "         \"to_maxp\" - в группу с наибольшей вероятностью события,\n",
    "         \"to_minp\" - в группу с наименьшей вероятностью события  \n",
    "         \n",
    "         \n",
    "- `oof_woe` - если указать oof_woe=True, то WoE кодирование будет происходить по кросс-валидации. Если же False, то сразу на всей обучающей выборке.\n",
    "\n",
    "- `n_folds` - количество фолдов для внутренней кроссвалидации\n",
    "\n",
    "\n",
    "- `n_jobs` - число процессов, которое будет использовать модель \n",
    "\n",
    "- `l1_grid_size` - в данной модели на одном из шагов используется отбор признаков LASSO. l1_base_step -- размер сетки для перебора C\n",
    "\n",
    "- `l1_exp_scale` - шкала сетки для L1 отбора. 4 соответствует макс значению C порядка 3-4. Увеличивать, если необходимо сделать менее регуляризованную модель\n",
    "\n",
    "- `imp_type` - способ определения значимости признаков -- features importance (\"feature_imp\" - в общем случае более сложная модель) или permutation importance (\"perm_imp\" - в общем случае более простая модель)\n",
    "\n",
    "- `regularized_refit` - после отбора признаков полученная модель пересчитывается на всех данных. Стоит ли включать L1 при этом. Если нет, то в интерпретируемом режиме модель будет итеративно переобучаться, пока все веса не станут отрицательны. Если да - то аналогичное будет получаться закручиванием L1. Может быть полезно ставить False если нужна стат модель, те p-value на оценки\n",
    "\n",
    "- `p_val` - допустимый уровень p_value на оценки модели при условии обучении стат модели (regularized_refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_woe = AutoWoE(\n",
    "    task=\"BIN\",\n",
    "    interpreted_model=True,\n",
    "    monotonic=False,\n",
    "    max_bin_count=5,\n",
    "    select_type=None,\n",
    "    pearson_th=0.9,\n",
    "    auc_th=0.505,\n",
    "    vif_th=10.0,\n",
    "    imp_th=0,\n",
    "    th_const=32,\n",
    "    force_single_split=True,\n",
    "    th_nan=0.01,\n",
    "    th_cat=0.005,\n",
    "    woe_diff_th=0.01,\n",
    "    min_bin_size=0.01,\n",
    "    min_bin_mults=(2, 4),\n",
    "    min_gains_to_split=(0.0, 0.5, 1.0),\n",
    "    auc_tol=1e-4,\n",
    "    cat_alpha=100,\n",
    "    cat_merge_to=\"to_woe_0\",\n",
    "    nan_merge_to=\"to_woe_0\",\n",
    "    oof_woe=True,\n",
    "    n_folds=6,\n",
    "    n_jobs=4,\n",
    "    l1_grid_size=20,\n",
    "    l1_exp_scale=6,\n",
    "    imp_type=\"feature_imp\",\n",
    "    regularized_refit=False,\n",
    "    p_val=0.05,\n",
    "    debug=False,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "auto_woe = ReportDeco(auto_woe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train` обучающая выборка\n",
    "\n",
    "- `target_name` - название целевой переменной\n",
    "\n",
    "- `features_type` - см выше описание дикта features_type. Возможно указание None для автозаполнения, но не рекомендуется\n",
    "\n",
    "- `group_kf` -  название колонки-группы для GroupKFold https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupKFold.html\n",
    "\n",
    "- `max_bin_count` - см выше описание дикта max_bin_count. Можно ничего не передавать, если специальных условий не предусмотрено. Общее для всех условние задано в __init__\n",
    "\n",
    "- `features_monotone_constraints` - см выше описание дикта features_monotone_constraints. Можно ничего не передавать, если специальных условий не предусмотрено. Общее для всех условние задано в __init__\n",
    "\n",
    "- `validation` - возможность использовать валидацию в построении/отборе признаков. Можно не передавать. На текущий момент используется для 1) отбора признаков по p-value при построении стат модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 63, number of negative: 5537\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 379\n",
      "[LightGBM] [Info] Number of data points in the train set: 5600, number of used features: 49\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011250 -> initscore=-4.476073\n",
      "[LightGBM] [Info] Start training from score -4.476073\n"
     ]
    }
   ],
   "source": [
    "auto_woe.fit(\n",
    "    train[features + [\"target\"]],\n",
    "    target_name=\"target\",\n",
    "    features_type=features_type,\n",
    "    group_kf=None,\n",
    "    max_bin_count=max_bin_count,\n",
    "    features_monotone_constraints=features_monotone_constraints,\n",
    "    validation=test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791178112786152"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = auto_woe.predict_proba(test)\n",
    "roc_auc_score(test[\"target\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791178112786152"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = auto_woe.predict_proba(test[[\"number_72\"]], report=False)\n",
    "roc_auc_score(test[\"target\"], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT\n",
      "  1 / (1 + EXP(-(\n",
      "    -4.517\n",
      "    -0.946*WOE_TAB.number_72\n",
      "  ))) as PROB,\n",
      "  WOE_TAB.*\n",
      "FROM \n",
      "    (SELECT\n",
      "    CASE\n",
      "      WHEN (number_72 IS NULL OR number_72 = 'NaN') THEN -0.974\n",
      "      WHEN number_72 <= 0.0 THEN 0.296\n",
      "      ELSE -1.96\n",
      "    END AS number_72\n",
      "  FROM table) as WOE_TAB\n"
     ]
    }
   ],
   "source": [
    "print(auto_woe.get_sql_inference_query(\"table\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Полезные методы модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `private_features_type` - типизация признаков\n",
    "- `get_woe` - рабиение на бины и WoE значения в них\n",
    "- `get_split` - границы разбиения. Особо полезен для категориальных признаков\n",
    "\n",
    "\n",
    "##### Замечание: \n",
    "ReportDeco - обертка для построения отчета. Она не обязательна для обучения и применения модели, но обязательна для построения отчета (см последнюю ячейку).\n",
    "Для доступа к атрибутам самой модели необходимо обратится к атрибуту auto_woe.model декоратора\n",
    "Все атрибуты объекта-модели так же доступны через объект-отчета.\n",
    "Однако в пикл отчета будет весить существенно больше, так что для сохранения модели на инференс стоит сохранять только auto_woe.model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Формирование отчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    }
   ],
   "source": [
    "report_params = {\n",
    "    \"automl_date_column\": \"report_month\",  # колонка с датой в формате params['datetimeFormat']\n",
    "    \"output_path\": \"./AUTOWOE_REPORT_1\",  # папка, куда сгенерится отчет и сложатся нужные файлы\n",
    "    \"report_name\": \"___НАЗВАНИЕ ОТЧЕТА___\",\n",
    "    \"report_version_id\": 1,\n",
    "    \"city\": \"Воронеж\",\n",
    "    \"model_aim\": \"___ЦЕЛЬ ПОСТРОЕНИЯ МОДЕЛИ___\",\n",
    "    \"model_name\": \"___НАЗВАНИЕ МОДЕЛИ___\",\n",
    "    \"zakazchik\": \"___ЗАКАЗЧИК___\",\n",
    "    \"high_level_department\": \"___ПОДРАЗДЕЛЕНИЕ___\",\n",
    "    \"ds_name\": \"___РАЗРАБОТЧИК МОДЕЛИ___\",\n",
    "    \"target_descr\": \"___ОПИСАНИЕ ЦЕЛЕВОГО СОБЫТИЯ___\",\n",
    "    \"non_target_descr\": \"___ОПИСАНИЕ НЕЦЕЛЕВОГО СОБЫТИЯ___\",\n",
    "}\n",
    "\n",
    "auto_woe.generate_report(report_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda_py38",
   "language": "python",
   "name": "anaconda_py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
